# CONFIG file with important modifiable parameters 
# Pick dataset
dset_name: cifar10 # can be cifar10, cifar100, svhn, emnist, inaturalist19, inaturalist21

# Novelty detector 
novelty_detector_name: incdfm # can be incdfm, dfm, mahal, odin or softmax

# for running oracle, set to False and set novelty_detector_name=dfm
prediction_propagation: True # if using the predicted labels instead of Ground truth labels for fitting PCA continually

## Validation threshold 
percentile_val_threshold: 95 # usually among (95,85,75,65)

# gpu
device: 1
# testing for debug or not
test_num: 10 # if debuging put integer > 0. else, -1 


# Training 
train_clf: False #For odin and softmax you need to set to True. 

# if not doing 1 class at a time
experiment_name: rebuttal_intraclass_2_by_2
num_per_task: 2
num_classes_first: 2
num_tasks: 2 ## set to -1 if wanting to use entire dataset 


# ------------------- Ocasionally modifiable 

# Experiment setup
percent_old_mix: 1.0 # Can be greater then 1.0 - percent which is comming from "old data" 
holdout_percent: 0.2 # (only when creating the experiment) if you are already passing a filepath, this parameter wont matter

batchsize: 50
num_epochs: 30
coreset_size: 5000 # if using keep_all_data, put corset_size = 0. 


val_percent: 0.1 # if leaving part of train as validation set


# Mix of old vs new in each task 1 --> num_new = num_old. 2 --> num_old = 2*num_new
# In case of unbalanced datasets. If set to True, will balance them 
equalize_labels: False
# In case of unbalanced datasets, will clip counts of classes with too many samples 
clip_labels: True
clip_max: 15000


# ---- paths + output
data_dir: ../../data
dir_results: ../../sandbox/Results_DFM_CL_Rebuttal
experiment_dir: ../../sandbox/Experiments_DFM_CL_Rebuttal

# ---- path to general config file 
standard_config_file: ../../src/configs_new/incDFM_rebuttal_fixed.yaml

