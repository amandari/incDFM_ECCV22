{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path_txt_orig = '/lab/tmpig21/u/arios/8dset_shell/shell_experiments/8dset/Shell_HalfClasses_8dset/'\n",
    "\n",
    "path_txt_out = '/lab/tmpig21/u/arios/8dset_shell/shell_experiments/8dset/Shell_agents_5classeach_8dset/'\n",
    "\n",
    "root_svhn = '/lab/arios/ProjIntel/incDFM/data/svhn/'\n",
    "\n",
    "\n",
    "# read by line numbers\n",
    "def get_lines(fp, line_numbers):\n",
    "    return (x for i, x in enumerate(fp) if i in line_numbers)\n",
    "\n",
    "\n",
    "\n",
    "# def read_SVHN_labels(root, subset, train=True):\n",
    "\n",
    "#     root = os.path.expanduser(root)\n",
    "    \n",
    "#     if train==True:\n",
    "#         filename = \"train_32x32.mat\"\n",
    "#     else:\n",
    "#         filename = \"test_32x32.mat\"\n",
    "\n",
    "        \n",
    "#     import scipy.io as sio\n",
    "#     # reading(loading) mat file as array\n",
    "#     loaded_mat = sio.loadmat(os.path.join(root, filename))\n",
    "#     # loading from the .mat file gives an np array of type np.uint8\n",
    "#     # converting to np.int64, so that we have a LongTensor after\n",
    "#     # the conversion from the numpy array\n",
    "#     # the squeeze is needed to obtain a 1D tensor\n",
    "#     labels = loaded_mat['y'].astype(np.int64).squeeze()\n",
    "\n",
    "#     # the svhn dataset assigns the class label \"10\" to the digit 0\n",
    "#     # this makes it inconsistent with several loss functions\n",
    "#     # which expect the class labels to be in the range [0, C-1]\n",
    "#     np.place(labels, labels == 10, 0)\n",
    "    \n",
    "#     labels = labels[subset]\n",
    "      \n",
    "#     return labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split= 'validation'\n",
    "files_per_dataset = os.listdir(path_txt_orig+split+'/')\n",
    "\n",
    "\n",
    "num_per_agent=5\n",
    "\n",
    "for file in files_per_dataset:\n",
    "    file = '%s/%s/%s'%(path_txt_orig,split,file)\n",
    "    task_agent = int(file.split('_')[-1].split('.')[0])\n",
    "    if 'txt' in file:\n",
    "        \n",
    "        # continue\n",
    "            \n",
    "        if task_agent==1:\n",
    "            classes = np.genfromtxt(file, delimiter='$').T[-1].astype(int)\n",
    "        else:\n",
    "            classes = np.genfromtxt(file, delimiter=' ').T[-1].astype(int)\n",
    "            \n",
    "        all_classes = np.unique(classes)\n",
    "        \n",
    "        class_splits = np.array_split(all_classes.tolist(), int(len(all_classes.tolist())/num_per_agent))\n",
    "        \n",
    "        \n",
    "        # ---- Inner loop for each agent \n",
    "        for agent, classes_agent in enumerate(class_splits):\n",
    "            inds_agent = np.where(np.in1d(classes, classes_agent))[0]\n",
    "            \n",
    "            filename_out = '%s/%s/nc_%s_task_%d_%d.txt'%(path_txt_out, split, split, task_agent, agent)\n",
    "            \n",
    "            with open(file, 'r') as fp:\n",
    "                \n",
    "                # read line 4 and 7\n",
    "                lines = get_lines(fp, inds_agent.tolist())\n",
    "                \n",
    "                lines = [l for l in lines]\n",
    "                \n",
    "                with open(filename_out, 'a') as outfp:\n",
    "                    outfp.writelines(lines)\n",
    "\n",
    "    else:\n",
    "        if split=='validation' or split=='test':\n",
    "            continue\n",
    "\n",
    "        filename_out = '%s/%s/nc_%s_task_%d_%d.npy'%(path_txt_out, split, split, task_agent, 0)\n",
    "    \n",
    "        inds = np.load(file)\n",
    "        \n",
    "        np.save(filename_out, inds)\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6656ba487fb895a60e5d4c5030343c34c763d6fe30d1a6683b717bdb1af8ff9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('incDFM_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
