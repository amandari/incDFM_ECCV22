{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from matplotlib import colors as mcolors\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "import itertools\n",
    "import copy\n",
    "import yaml\n",
    "import pickle\n",
    "import torchvision.transforms as TF\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import tforms\n",
    "import feature_extraction.feature_extraction_utils as futils\n",
    "from feature_extraction.Network_Latents_Wrapper import NetworkLatents\n",
    "# import classifier as clf\n",
    "\n",
    "\n",
    "import novelty_dfm_CL.novelty_detector as novel\n",
    "import novelty_dfm_CL.novelty_eval as novelval \n",
    "import novelty_dfm_CL.classifier as clf\n",
    "import novelty_dfm_CL.novelty_utils as novelu\n",
    "import novelty_dfm_CL.incDFM as novelinc\n",
    "\n",
    "\n",
    "import tforms\n",
    "import memory as mem\n",
    "import utils\n",
    "import datasets as dset\n",
    "import novelty_dfm_CL.datasets_holdout as dseth\n",
    "import datasets_utils as dsetutils\n",
    "\n",
    "import novelty_dfm_CL.scoring_multi_threshold as ThScores\n",
    "\n",
    "\n",
    "from novelty_dfm_CL.novelty_eval import acuracy_report, scores_metrics_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "utils.seed_torch(0)\n",
    "\n",
    "\n",
    "general_config_path = '../src/configs/DFM_CL_n_baselines_1class_loop.yaml' # path to file \n",
    "\n",
    "\n",
    "with open(general_config_path) as fid:\n",
    "        args = Namespace(**yaml.load(fid, Loader=yaml.SafeLoader))\n",
    "\n",
    "torch.set_num_threads(args.num_threads)\n",
    "pin_memory=False\n",
    "\n",
    "# set up save\n",
    "args = utils.config_saving(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_task [0, 1] 1 0\n",
      "seq_tasks:  [[0, 1], [2]] 1\n",
      "*****Prep Data*****\n",
      "Prepare DSET npy paths\n",
      "counts labels Counter({4: 158463, 1: 47867, 3: 41204, 5: 14513, 0: 3912, 2: 2284})\n",
      "equilize counts\n",
      "[  2284  41204   3912  14513  47867 158463] [2 3 0 5 1 4]\n",
      "min_count 3912\n",
      "counts labels Counter({3: 3912, 0: 3912, 5: 3912, 1: 3912, 4: 3912, 2: 2284})\n",
      "tasks_list [array([ 47101,  46429,  45417, ...,  77260, 106396,  67178]), array([ 289, 1017, 2048, ...,  763,  835, 1653])] 2\n",
      "num_samples_task 7824\n",
      "num_samples_task 2284\n",
      "prepared filelists 0.7284934520721436\n",
      "None\n",
      "number tasks 2\n",
      "prepared datasets 140.84853649139404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start=time.time()\n",
    "# 1) ----- Dataset \n",
    "if not hasattr(args, 'experiment_filepath'):\n",
    "    args.experiment_filepath = None # have dictionary for defaults???\n",
    "if not hasattr(args, 'experiment_name'):\n",
    "    args.experiment_name = None # have dictionary for defaults??\n",
    "\n",
    "\n",
    "if args.holdout:\n",
    "    # load holdout dset\n",
    "    datasets_use = dseth.call_dataset_holdout(args.dset_name, args.data_dir, args.experiment_dir, experiment_filepath=args.experiment_filepath, experiment_name=args.experiment_name, \n",
    "                                            holdout_percent=args.holdout_percent,  max_holdout=args.max_holdout, scenario=args.scenario, \n",
    "                                            scenario_classif=args.scenario_classif, exp_type=args.exp_type, num_per_task=args.num_per_task, num_classes_first=args.num_classes_first, \n",
    "                                            type_l_cifar=args.type_l_cifar, num_tasks=args.num_tasks, num_tasks_cifar=args.num_tasks_cifar, \n",
    "                                            shuffle=args.shuffle_order, preload=args.preload, keep_all_data=args.keep_all_data, equalize_labels=args.equalize_labels)\n",
    "\n",
    "    if args.keep_all_data==True:\n",
    "        train_datasets, train_holdout_datasets, train_datasets_new_only, test_datasets, list_tasks, list_tasks_targets, dset_prep = datasets_use\n",
    "    else:\n",
    "        train_datasets, train_holdout_datasets, test_datasets, list_tasks, list_tasks_targets, dset_prep = datasets_use\n",
    "\n",
    "else:\n",
    "    datasets_use = dset.call_dataset(args.dset_name, args.data_dir, args.experiment_dir, experiment_filepath=args.experiment_filepath, experiment_name=args.experiment_name, \n",
    "                                                    num_classes_first=args.num_classes_first, keep_all_data=args.keep_all_data, \n",
    "                                                    scenario=args.scenario, scenario_classif=args.scenario_classif, \n",
    "                                                    exp_type=args.exp_type, num_per_task=args.num_per_task,\n",
    "                                                    type_l_cifar=args.type_l_cifar, num_tasks_cifar=args.num_tasks_cifar, \n",
    "                                                    shuffle=args.shuffle_order, preload=args.preload)\n",
    "    if args.keep_all_data==True:\n",
    "        train_datasets, train_datasets_new_only, test_datasets, list_tasks, list_tasks_targets, dset_prep = datasets_use\n",
    "    else:\n",
    "        train_datasets, test_datasets, list_tasks, list_tasks_targets, dset_prep = datasets_use\n",
    "\n",
    "\n",
    "\n",
    "args.dset_prep = dset_prep\n",
    "if args.num_tasks>0:\n",
    "    num_tasks = args.num_tasks\n",
    "else:\n",
    "    num_tasks = len(train_datasets)\n",
    "    \n",
    "    \n",
    "\n",
    "test_loaders = [torch.utils.data.DataLoader(test_datasets[t], batch_size=args.batchsize_test,\n",
    "                                                shuffle=True, num_workers=args.num_workers) for t in range(num_tasks)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_tasks_targets [[0, 1], [2]]\n",
      "Get scores for novelty detector\n",
      "list_tasks [[0, 1]]\n",
      "Task 1 num_old 1372 num_new 1372 num_old_per_task [1372]\n",
      "Data set up 166.0698642730713\n",
      "load contrastive backbone\n",
      "Will fetch activations from:\n",
      "base.8, average pooled by -1\n",
      "Network set up 168.5375587940216\n",
      "Novelty Detector set up 168.54024457931519\n",
      "Memory set up 168.5408673286438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('list_tasks_targets', list_tasks_targets)\n",
    "# sys.exit()\n",
    "\n",
    "if args.holdout:\n",
    "    old_dsets = train_holdout_datasets\n",
    "    use_old_dsets = copy.copy(train_holdout_datasets)\n",
    "else:\n",
    "    old_dsets = test_datasets\n",
    "    use_old_dsets = copy.copy(test_datasets)\n",
    "\n",
    "\n",
    "num_old_per_task={}\n",
    "ratio_per_task={}\n",
    "for t_w in range(1,num_tasks):\n",
    "    print('Get scores for novelty detector')\n",
    "    # how much to mix from old and new in one task\n",
    "    num_old, num_new, num_old_per_task_pt = novelu.num_mix_old_novelty(args.percent_old_mix, train_datasets[t_w], old_dsets[:t_w], t_w, list_tasks_targets[:t_w])\n",
    "    print('Task', t_w, 'num_old', num_old,  'num_new', num_new, 'num_old_per_task', num_old_per_task_pt)\n",
    "    num_old_per_task[t_w] = num_old_per_task_pt\n",
    "    ratio_per_task[t_w] = num_new/(num_old+num_new)\n",
    "\n",
    "print('Data set up', time.time()-start)\n",
    "# sys.exit()\n",
    "\n",
    "\n",
    "# 2) ------ Network \n",
    "if len(args.fc_sizes)>0:\n",
    "    fc_sizes = args.fc_sizes.split(\",\")\n",
    "    fc_sizes = [int(x) for x in fc_sizes]\n",
    "else:\n",
    "    fc_sizes = []\n",
    "network = clf.Resnet(dset_prep['total_classes'], resnet_arch=args.net_type, FC_layers=fc_sizes, base_freeze=True)\n",
    "network = network.to(args.device)\n",
    "dfm_inputs = args.dfm_layers_input.split(\",\")\n",
    "dfm_layers_factors = str(args.dfm_layers_factors)\n",
    "dfm_layers_factors = dfm_layers_factors.split(',')\n",
    "dfm_inputs_factors = {}\n",
    "for n in range(len(dfm_inputs)):\n",
    "    dfm_inputs_factors[dfm_inputs[n]]=int(dfm_layers_factors[n]) #adaptive pooling \n",
    "network_inner = NetworkLatents(network, dfm_inputs, pool_factors=dfm_inputs_factors)\n",
    "print('Network set up', time.time()-start)\n",
    "\n",
    "\n",
    "args.patience_lr = int(np.ceil(args.schedule_patience_perepoch*args.num_epochs))\n",
    "\n",
    "# x= torch.rand((50,3,224,224)).to(args.device)\n",
    "# print(network.base(x).shape)\n",
    "# # print(futils.layer_names(network))\n",
    "\n",
    "\n",
    "# 3) ---- Novelty\n",
    "args.detector_params['target_ind']=dset_prep['scenario_classif']\n",
    "args.detector_params['device']=args.device\n",
    "args.detector_params['w_old_i'] = args.w_old_i # only for tugIncDFM\n",
    "if args.novelty_detector_name=='odin':\n",
    "    args.detector_params['base_network']=network #simple network (not wrapper) - Is this problematic? TODO\n",
    "    args.detector_params['num_classes']=dset_prep['total_classes']\n",
    "    args.detector_params['criterion']= nn.CrossEntropyLoss()\n",
    "    args.detector_params['num_epochs']=args.num_epochs\n",
    "    args.detector_params['train_technique']=args.train_technique\n",
    "    args.detector_params['lr']=args.lr\n",
    "    args.detector_params['patience_lr'] = args.patience_lr\n",
    "    args.detector_params['schedule_decay'] = args.schedule_decay\n",
    "    args.detector_params['step_size_epoch_lr']= args.step_size_epoch_lr\n",
    "    args.detector_params['gamma_step_lr']= args.gamma_step_lr\n",
    "\n",
    "\n",
    "\n",
    "noveltyResults = novelval.save_novelty_results(num_tasks, args.experiment_name_plot, args.dir_save)\n",
    "novelty_detector = novel.NoveltyDetector().create_detector(type=args.novelty_detector_name, params=args.detector_params)\n",
    "print('Novelty Detector set up', time.time()-start)\n",
    "\n",
    "\n",
    "\n",
    "# 4) ---- Memory (if applicable for recomputing DFM per task)\n",
    "# Use raw images in memory\n",
    "coreset = None\n",
    "if args.coreset_size>0:\n",
    "    if args.use_image_as_input:\n",
    "        raw_sizes = {'svhn':32, 'cifar10':32, 'cifar100':32}\n",
    "        input_size = 3*(raw_sizes[args.dset_name]**2)\n",
    "    else:\n",
    "        input_size = network.feat_size  \n",
    "    if args.coreset_size>0 and args.keep_all_data==False:\n",
    "        if args.coreset_size_MB>0:\n",
    "            coreset_size = utils.memory_equivalence(args.coreset_size_MB, input_size, quantizer_dict=None)\n",
    "        else:\n",
    "            coreset_size = args.coreset_size\n",
    "        coreset = mem.CoresetDynamic(coreset_size, target_ind= dset_prep['scenario_classif'], homog_ind=dset_prep['homog_ind'], device=args.device)\n",
    "print('Memory set up', time.time()-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "######### task 0 ############\n",
      "###############################\n",
      "##########epoch 0###########\n",
      "Number batches:  94\n",
      "Train Epoch: 0 [0/94 (0.000)]\tLoss: 1.8162\tAcc_Train_new:0.000\n",
      "Train Epoch: 0 [10/94 (10.638)]\tLoss: 0.5017\tAcc_Train_new:0.780\n",
      "Train Epoch: 0 [20/94 (21.277)]\tLoss: 0.3940\tAcc_Train_new:0.760\n",
      "Train Epoch: 0 [30/94 (31.915)]\tLoss: 0.2555\tAcc_Train_new:0.900\n",
      "Train Epoch: 0 [40/94 (42.553)]\tLoss: 0.2302\tAcc_Train_new:0.920\n",
      "Train Epoch: 0 [50/94 (53.191)]\tLoss: 0.3011\tAcc_Train_new:0.840\n",
      "Train Epoch: 0 [60/94 (63.830)]\tLoss: 0.3756\tAcc_Train_new:0.860\n",
      "Train Epoch: 0 [70/94 (74.468)]\tLoss: 0.3541\tAcc_Train_new:0.820\n",
      "Train Epoch: 0 [80/94 (85.106)]\tLoss: 0.2277\tAcc_Train_new:0.860\n",
      "Train Epoch: 0 [90/94 (95.745)]\tLoss: 0.3120\tAcc_Train_new:0.860\n",
      "**************TEST****************\n",
      "*********************************************************\n",
      "****************Testing task 0************\n",
      "*********************************************************\n",
      "\n",
      " Per-Task Test set: Accuracy: {1470}/{1564} = {93.9898}\n",
      "\n",
      "\n",
      " ******Test set: Average Accuracy: 93.9898*****\n",
      "\n",
      "Generate features for novelty evaluation and coreset\n",
      "Append data to memory\n",
      "*******Appending to CORESET******\n",
      "total_size 5000 room_new 5000 room_left 5000 coreset now 0\n",
      "coreset_im torch.Size([4695, 2048])\n",
      "###############################\n",
      "######### task 1 ############\n",
      "###############################\n",
      "Get scores for novelty detector\n",
      "Iter 1 - Acc  All/Precision 0.535/0.618: inds_pred_novel 411/411/1372\n",
      "inds_nonlabeled (2333,) (411,)\n",
      "Iter 2 - Acc  All/Precision 0.657/0.763: inds_pred_novel 411/822/1372\n",
      "inds_nonlabeled (1922,) (822,)\n",
      "Iter 3 - Acc  All/Precision 0.756/0.785: inds_pred_novel 411/1233/1372\n",
      "inds_nonlabeled (1511,) (1233,)\n",
      "Iter 4 - Acc  All/Precision 0.784/0.784: inds_pred_novel 139/1372/1372\n",
      "New task 1, AUROC = 0.812, AUPR = 0.713, AUPR_NORM = 0.713\n",
      "new_scores [0.4828798  0.36002811 1.08390871 ... 1.08686697 2.86807243 1.60449234]\n",
      "old_scores [0.4390308  1.30159702 0.55483196 ... 0.50154711 0.52155312 0.5128482 ]\n",
      "DFM Results -  Auroc 0.812, Aupr 0.713, Aupr_norm 0.713\n",
      "Average Accuracy per class old 0.8280\n",
      "Use Predicted Labels for Propagation/DFM Fit\n",
      "##########epoch 0###########\n",
      "Number batches:  55\n",
      "Train Epoch: 0 [0/55 (0.000)]\tLoss: 11.7155\tAcc_Train_new:0.000\tAcc_Train_coreset:0.840\n",
      "Train Epoch: 0 [10/55 (18.182)]\tLoss: 1.1572\tAcc_Train_new:1.000\tAcc_Train_coreset:0.000\n",
      "Train Epoch: 0 [20/55 (36.364)]\tLoss: 0.8166\tAcc_Train_new:0.760\tAcc_Train_coreset:0.680\n",
      "Train Epoch: 0 [30/55 (54.545)]\tLoss: 0.8556\tAcc_Train_new:0.840\tAcc_Train_coreset:0.320\n",
      "Train Epoch: 0 [40/55 (72.727)]\tLoss: 0.8080\tAcc_Train_new:0.800\tAcc_Train_coreset:0.480\n",
      "Train Epoch: 0 [50/55 (90.909)]\tLoss: 0.5812\tAcc_Train_new:0.800\tAcc_Train_coreset:0.640\n",
      "**************TEST****************\n",
      "*********************************************************\n",
      "****************Testing task 0************\n",
      "*********************************************************\n",
      "\n",
      " Per-Task Test set: Accuracy: {622}/{1564} = {39.7698}\n",
      "\n",
      "*********************************************************\n",
      "****************Testing task 1************\n",
      "*********************************************************\n",
      "\n",
      " Per-Task Test set: Accuracy: {456}/{456} = {100.0000}\n",
      "\n",
      "\n",
      " ******Test set: Average Accuracy: 53.3663*****\n",
      "\n",
      "Generate features for novelty evaluation and coreset\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "per_task_results = {'scores':{}, 'scores_dist':{}, 'gt_novelty':{}, 'gt':{}, 'inds':{}, 'threshold':{}, 'preds':{}}\n",
    "\n",
    "per_task_results = Namespace(**per_task_results)\n",
    "\n",
    "num_classes = 0\n",
    "for t in range(num_tasks):\n",
    "    print('###############################')\n",
    "    print('######### task %d ############'%(t))\n",
    "    print('###############################')\n",
    "    current_task = list_tasks_targets[t]\n",
    "\n",
    "\n",
    "    # ------- Set up data \n",
    "    if t>0 and (coreset is not None):\n",
    "        batchsize_new =  int(args.batchsize*0.5)\n",
    "        batchsize_old = args.batchsize - batchsize_new\n",
    "        # --- wrap old data features (latent)\n",
    "        dataset_old = dsetutils.DSET_wrapper_Replay(coreset.coreset_im, coreset.coreset_t, latents=coreset.coreset_latents, transform=args.tf_coreset)\n",
    "        loader_old = torch.utils.data.DataLoader(dataset_old, batch_size=batchsize_old,\n",
    "                                                shuffle=True, num_workers=args.num_workers)\n",
    "    else:\n",
    "        batchsize_new = args.batchsize\n",
    "        batchsize_old = 0\n",
    "        loader_old = None\n",
    "        \n",
    "\n",
    "    if t>0:\n",
    "        # 1) get appropriate \"current data\"\n",
    "        if args.keep_all_data==True:\n",
    "            new_data = train_datasets_new_only[t]\n",
    "        else:\n",
    "            new_data = train_datasets[t]\n",
    "\n",
    "        print('Get scores for novelty detector')\n",
    "        for t_old in range(t):\n",
    "            use_old_dsets[t_old].select_random_subset(num_old_per_task[t][t_old])\n",
    "\n",
    "        current_dset = novelu.CurrentTask(new_data, use_old_dsets[:t], use_coarse=dset_prep['use_coarse'])\n",
    "\n",
    "        current_loader = torch.utils.data.DataLoader(current_dset, batch_size=args.batchsize_test,\n",
    "                                                shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "        params_score = {'layer':args.dfm_layers_input, 'feature_extractor':network_inner, \\\n",
    "            'base_apply_score':True, 'target_ind':dset_prep['scenario_classif'], 'device': args.device}\n",
    "\n",
    "\n",
    "        if args.threshold_type=='simple':\n",
    "            # 2) Threshold Novel/Old - Binary prediction \n",
    "            if args.novelty_detector_name=='dfm' or args.novelty_detector_name=='mahal':\n",
    "                results_novelty = novelval.evaluate_simple_CL(t, novelty_detector, noveltyResults, params_score, current_loader)\n",
    "            elif args.novelty_detector_name=='odin':\n",
    "                results_novelty = novelval.evaluate_odin_CL(t, novelty_detector, noveltyResults, params_score, current_loader)\n",
    "                # invert scores for ODIN so that high scores are novelty (1)\n",
    "            threshold_percentile_effective = int(np.floor(ratio_per_task[t]*100))\n",
    "            inds_pred_novel,_ = novelinc.Threshold_n_Select_Simple(t, results_novelty, th_percentile_score=threshold_percentile_effective, novelty_detector_name=args.novelty_detector_name, \n",
    "                                th_percentile_confidence=args.th_percentile_confidence,  metric_confidence=(args.metric_confidence, args.metric_confidence_direction_novel))\n",
    "            threshold_used = args.threshold_percentile\n",
    "            acc_overall, acc_novel, prec_novel, recall_novel = noveltyResults.compute_accuracies(t, 0, inds_pred_novel, results_novelty.gt_novelty)\n",
    "\n",
    "            print('Binary Pseudolabeling - acc_overall: %.4f, acc_novel: %.4f, prec_novel: %.4f, recall_novel: %.4f' %(acc_overall, acc_novel, prec_novel, recall_novel))\n",
    "\n",
    "        else:\n",
    "            args.params_score = Namespace(**params_score)\n",
    "            args.num_samples = current_dset.__len__()\n",
    "            args.th_percentile = args.threshold_percentile\n",
    "            args.w = args.w_score\n",
    "            args.current_old_new_ratio = ratio_per_task[t]\n",
    "            # Threshold_n_Select_Iters(params)\n",
    "            if args.alg_dfm == 'simple':\n",
    "                SelectTh = novelinc.Threshold_n_Select_Iters(args)\n",
    "            elif args.alg_dfm == 'tug':\n",
    "                SelectTh = novelinc.Threshold_Tug_incDFM(args)\n",
    "                \n",
    "            inds_pred_novel,_ = SelectTh.select_novel(t, current_dset, novelty_detector, noveltyResults)\n",
    "            results_novelty = SelectTh.evaluate_CL(t, current_dset, novelty_detector, noveltyResults)\n",
    "            threshold_used = args.max_threshold_total\n",
    "        \n",
    "\n",
    "        # store results per task \n",
    "        per_task_results.scores_dist[t] = results_novelty.scores_dist\n",
    "        per_task_results.scores[t] = results_novelty.scores\n",
    "        per_task_results.gt_novelty[t] = results_novelty.gt_novelty\n",
    "        per_task_results.gt[t] = results_novelty.gt\n",
    "        per_task_results.inds[t] = results_novelty.dset_inds\n",
    "        per_task_results.threshold[t] = threshold_used\n",
    "\n",
    "        preds_array = np.zeros(results_novelty.scores.shape)\n",
    "        preds_array[inds_pred_novel]=1\n",
    "        per_task_results.preds[t] = preds_array\n",
    "\n",
    "\n",
    "        # 3) Pseudolabel \"Novel\" Samples\n",
    "        if args.prediction_propagation:\n",
    "            print('Use Predicted Labels for Propagation/DFM Fit')\n",
    "            loader_new = torch.utils.data.DataLoader(novelu.NovelTask(t, num_classes, current_dset, pred_novel_inds=inds_pred_novel), batch_size=batchsize_new,\n",
    "                                                    shuffle=True, num_workers=args.num_workers)\n",
    "        else:\n",
    "            inds_gt_novel = np.where(current_dset.novelty_y==1)[0]\n",
    "            print('Use Ground Truth Labels for Propagation/DFM Fit')\n",
    "            loader_new = torch.utils.data.DataLoader(novelu.NovelTask(t, num_classes, current_dset, pred_novel_inds=inds_gt_novel), batch_size=batchsize_new,\n",
    "                                                    shuffle=True, num_workers=args.num_workers)\n",
    "\n",
    "    else:\n",
    "        loader_new = torch.utils.data.DataLoader(novelu.NovelTask(t, num_classes, train_datasets[t], use_coarse=dset_prep['use_coarse']), \\\n",
    "            batch_size=batchsize_new, shuffle=True, num_workers=args.num_workers)\n",
    "\n",
    "\n",
    "    # if training classifier or doing finetuning of backbone \n",
    "    if args.train_clf:\n",
    "        clf.train(t, args, novelty_detector, network_inner, loader_old, loader_new, test_loaders, train_technique=args.train_technique)\n",
    "\n",
    "    #  call training loop with one liner \n",
    "    args, temp_train_loader = novelu.temporary_loader_novelty(args, loader_new, coreset)\n",
    "\n",
    "\n",
    "\n",
    "    print('Generate features for novelty evaluation and coreset')\n",
    "    # target_ind, homog_ind=1 because they are wrapped by NovelTask \n",
    "    processed_data = futils.extract_features(network_inner, temp_train_loader, \\\n",
    "        target_ind=1, homog_ind=1, \n",
    "        device=args.device, use_raw_images=args.use_image_as_input, raw_image_transform=args.add_tf)\n",
    "\n",
    "\n",
    "\n",
    "    # ------ update coreset (if applicable)\n",
    "    if t<num_tasks-1:\n",
    "        if coreset is not None:\n",
    "            print('Append data to memory')\n",
    "            coreset.append_memory(processed_data, current_task)\n",
    "            print('coreset_im', coreset.coreset_im.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # ----Update memory and Novelty detector\n",
    "    if t<num_tasks-1:\n",
    "        if args.novelty_detector_name=='dfm':\n",
    "            dfm_x = processed_data[0][args.dfm_layers_input]\n",
    "            dfm_y = processed_data[1]\n",
    "            if args.finetune_backbone=='all':\n",
    "                novelty_detector, dfm_x, dfm_y = novelu.reprocess_data_novelty(args, dfm_x, dfm_y, network_inner, coreset)\n",
    "            novelty_detector.fit_total(dfm_x.T, dfm_y)\n",
    "\n",
    "        elif args.novelty_detector_name=='mahal':\n",
    "            if t>0:\n",
    "                # join processed_data with coreset_data\n",
    "                mahal_x = torch.cat((processed_data[0][args.dfm_layers_input],coreset.coreset_im), dim=0)\n",
    "                mahal_y = torch.cat((processed_data[1],coreset.coreset_t))\n",
    "            else:\n",
    "                mahal_x = processed_data[0][args.dfm_layers_input]\n",
    "                mahal_y = processed_data[1]\n",
    "            novelty_detector.fit_total(mahal_x.T, mahal_y)\n",
    "\n",
    "\n",
    "\n",
    "    num_classes = num_classes + len(current_task)\n",
    "\n",
    "\n",
    "    # print('PCA mats', novelty_detector.pca_mats)\n",
    "    # if t==1:\n",
    "    #     sys.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/results_tasks.pickle'%(args.dir_save), 'wb') as handle:\n",
    "    pickle.dump(per_task_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05b150e87e16a7f15e68a52cad20b8449e4511c9ed1c6048915793505d6c322d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('remind_proj': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
