{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 137600,\n",
       "          1: 120800,\n",
       "          2: 1300,\n",
       "          3: 1050,\n",
       "          4: 8450,\n",
       "          5: 4200,\n",
       "          6: 12850,\n",
       "          7: 1750,\n",
       "          8: 210900}),\n",
       " (498900,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as TF\n",
    "from collections import Counter\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Tuple\n",
    "\n",
    "\n",
    "def exclude_inds_2021(labels):\n",
    "    exclude_lbls = [0,9,10,11]\n",
    "\n",
    "    indices_all = np.arange(labels.shape[0])\n",
    "    exclude_inds = []\n",
    "    for lb in exclude_lbls:\n",
    "        inds = np.where(labels==lb)[0].astype(int)\n",
    "        exclude_inds.extend(inds.tolist())\n",
    "    \n",
    "    indices_keep = np.setdiff1d(indices_all, np.array(exclude_inds))\n",
    "    \n",
    "    return indices_keep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "  \n",
    "\n",
    "class WrapNaturalist(datasets.INaturalist):\n",
    "    \n",
    "    def __init__(self, root: str, version: str = \"2021_train\", target_type: Union[List[str], str] = \"full\", \\\n",
    "        transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None:\n",
    "        super().__init__(root, version, target_type, transform, target_transform, download)\n",
    "        \n",
    "        self.target_transform = target_transform\n",
    "        self.version = version\n",
    "        \n",
    "        if '19' in self.version:\n",
    "            indices_path = root+'/'+'2019_valid_indices.npy'\n",
    "        elif '21' in self.version:\n",
    "            self.map_target_2021 = {1:0,2:1,3:2,4:3,5:4,6:5,7:6,8:7,12:8}\n",
    "            self.target_transform =  transforms.Lambda(lambda x: self.map_target_2021[x])\n",
    "            indices_path = root+'/'+'2021_valid_indices.npy'\n",
    "            \n",
    "        self.indices_path = indices_path\n",
    "        self.indices_all = np.load(indices_path)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.indices_all.shape[0]\n",
    "        \n",
    "    def __getindex__(self, idx):\n",
    "        \n",
    "        idx = self.indices_all[idx]\n",
    "        \n",
    "        cat_id, _ = self.index[idx]\n",
    "\n",
    "        target = []\n",
    "        # target_name = []\n",
    "        for t in self.target_type:\n",
    "            if t == \"full\":\n",
    "                target.append(cat_id)\n",
    "            else:\n",
    "                target.append(self.categories_map[cat_id][t])\n",
    "                # if '21' in self.version:\n",
    "                #     target_name.append(self.all_categories[cat_id].split('_')[2])\n",
    "        target = tuple(target) if len(target) > 1 else target[0]\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        \n",
    "        return target\n",
    "    \n",
    "    \n",
    "    def __getitem_wrap__(self, idx):\n",
    "        \n",
    "        idx = self.indices_all[idx]\n",
    "        \n",
    "        im, target = self.__getitem__(idx)\n",
    "        \n",
    "        # if self.target_transform is not None:\n",
    "        #     target = self.target_transform(target)\n",
    "            \n",
    "        return im, target\n",
    "    \n",
    "    \n",
    "    def __getlabels_2019__(self):\n",
    "        \n",
    "        self.labels = np.zeros((self.__len__(),)).astype(int)\n",
    "        for i in range(self.__len__()):\n",
    "            target = self.__getindex__(i)            \n",
    "            self.labels[i]=target\n",
    "            \n",
    "        return self.labels\n",
    "            \n",
    "            \n",
    "    def __getlabels_2021__(self):\n",
    "        self.labels = np.zeros((self.__len__(),)).astype(int)\n",
    "        for i in range(self.__len__()):\n",
    "            target = self.__getindex__(i)            \n",
    "            self.labels[i]=target\n",
    "            # self.labels_map.append((target, name))\n",
    "                    \n",
    "        return self.labels\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "class inaturalist_normalize():\n",
    "    def __init__(self):\n",
    "        self.tf = TF.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.tf(img)\n",
    "\n",
    "\n",
    "class inaturalist_train():\n",
    "    \"\"\"Pre-processing for inaturalist training.\n",
    "    \"\"\"\n",
    "    # TODO maybe the tranform topilimage is messing up the normalization!\n",
    "    def __init__(self):\n",
    "        self.tf = TF.Compose([TF.Resize(256), TF.CenterCrop(224), TF.RandomHorizontalFlip(), TF.ToTensor(), \n",
    "                            #   inaturalist_normalize(),\n",
    "                              ])\n",
    "        # self.tf = TF.Compose([core50_normalize()])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.tf(img)\n",
    "    \n",
    "tapply = inaturalist_train()\n",
    "\n",
    "    \n",
    "dataroot = '/lab/arios/ProjIntel/incDFM/data/inaturalist21/'\n",
    "\n",
    "\n",
    "dset_index = WrapNaturalist(dataroot, version='2021_train_mini', target_type=['phylum'], \\\n",
    "    transform=tapply, target_transform=None, download=False)\n",
    "labels = dset_index.__getlabels_2021__()\n",
    "    \n",
    "\n",
    "# dset_index = WrapNaturalist(dataroot, version='2019', target_type=['super'], \\\n",
    "#     transform=tapply, target_transform=None, download=False)\n",
    "# labels = dset_index.__getlabels_2019__()\n",
    "\n",
    "Counter(labels), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class inaturalistTask():\n",
    "    def __init__(self, dataroot, dset_name='inaturalist19', tasklist='task_indices.npy', transform=None, \\\n",
    "        returnIDX=False, train=True, preload=False):\n",
    "        \"\"\" \n",
    "        dataset for each individual task\n",
    "        \"\"\"\n",
    "        self.preload = preload\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "        self.transform_preload = transform\n",
    "        self.dset_name = dset_name\n",
    "        \n",
    "        if self.dset_name == 'inaturalist19':\n",
    "            self.dataset = WrapNaturalist(dataroot, version='2019', target_type=['super'], \\\n",
    "                                    transform=transform, download=False)\n",
    "            _ = self.dataset.__getlabels_2019__()\n",
    "        elif self.dset_name == 'inaturalist21':\n",
    "            self.dataset = WrapNaturalist(dataroot, version='2021_train_mini', target_type=['phylum'], \\\n",
    "                                    transform=transform, download=False)\n",
    "            _ = self.dataset.__getlabels_2021__()\n",
    "\n",
    "        # have option of loading multiple tasklists if the case\n",
    "        if isinstance(tasklist, list):\n",
    "            self.indices_task_init=[]\n",
    "            for l in tasklist:\n",
    "                self.indices_task_init.append(np.load(l))\n",
    "            self.indices_task_init = np.concatenate(self.indices_task_init)\n",
    "        else:\n",
    "            self.indices_task_init = np.load(tasklist)\n",
    "            \n",
    "\n",
    "        self.returnIDX = returnIDX\n",
    "        \n",
    "        self.indices_task = np.copy(self.indices_task_init)\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.indices_task.shape[0]\n",
    "\n",
    "    def select_random_subset(self, random_num):\n",
    "\n",
    "        inds_keep = np.random.permutation(np.arange(self.indices_task_init.shape[0]))[:random_num]\n",
    "\n",
    "        self.indices_task = self.indices_task_init[inds_keep]\n",
    "        \n",
    "    def select_specific_subset(self, indices_select):\n",
    "        \n",
    "        self.indices_task = self.indices_task_init[indices_select]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        idx = self.indices_task[idx]\n",
    "        print('idx', idx)\n",
    "        im, class_lbl = self.dataset.__getitem_wrap__(idx)\n",
    "\n",
    "        # assert self.dataset.labels[idx] == class_lbl\n",
    "        \n",
    "        if self.returnIDX:\n",
    "            return im, class_lbl, class_lbl, idx\n",
    "            \n",
    "        return im, class_lbl, class_lbl\n",
    "\n",
    "\n",
    "\n",
    "indices_task = '/lab/arios/ProjIntel/incDFM/src/novelty_dfm_CL/Experiments_DFM_CL/inaturalist21/holdout_0.20_val_0.10/train/nc_train_task_0.npy'\n",
    "\n",
    "dset_t = inaturalistTask(dataroot, dset_name='inaturalist21', tasklist=indices_task, transform=tapply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx 40552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8588, 0.8745, 0.8745,  ..., 0.5137, 0.5412, 0.5608],\n",
       "          [0.8588, 0.8627, 0.8588,  ..., 0.4824, 0.5176, 0.5294],\n",
       "          [0.8667, 0.8549, 0.8392,  ..., 0.4667, 0.4784, 0.4863],\n",
       "          ...,\n",
       "          [0.7176, 0.6980, 0.6784,  ..., 0.3294, 0.3020, 0.3059],\n",
       "          [0.7059, 0.6627, 0.6353,  ..., 0.2627, 0.2627, 0.2510],\n",
       "          [0.6706, 0.6275, 0.6039,  ..., 0.2863, 0.2863, 0.2784]],\n",
       " \n",
       "         [[0.8431, 0.8510, 0.8471,  ..., 0.4549, 0.4824, 0.4980],\n",
       "          [0.8392, 0.8353, 0.8275,  ..., 0.4275, 0.4627, 0.4706],\n",
       "          [0.8392, 0.8275, 0.8078,  ..., 0.4157, 0.4235, 0.4353],\n",
       "          ...,\n",
       "          [0.6784, 0.6588, 0.6471,  ..., 0.2549, 0.2392, 0.2431],\n",
       "          [0.6667, 0.6235, 0.6000,  ..., 0.2118, 0.2196, 0.2118],\n",
       "          [0.6275, 0.5882, 0.5647,  ..., 0.2510, 0.2549, 0.2471]],\n",
       " \n",
       "         [[0.8000, 0.8039, 0.8000,  ..., 0.3922, 0.4235, 0.4392],\n",
       "          [0.7961, 0.7882, 0.7765,  ..., 0.3686, 0.4039, 0.4118],\n",
       "          [0.7961, 0.7843, 0.7608,  ..., 0.3608, 0.3686, 0.3765],\n",
       "          ...,\n",
       "          [0.6431, 0.6235, 0.6078,  ..., 0.2000, 0.1882, 0.1922],\n",
       "          [0.6275, 0.5882, 0.5647,  ..., 0.1686, 0.1843, 0.1843],\n",
       "          [0.5882, 0.5490, 0.5294,  ..., 0.2157, 0.2314, 0.2235]]]),\n",
       " 0,\n",
       " 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_t.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8588, 0.8745, 0.8745,  ..., 0.5137, 0.5412, 0.5608],\n",
       "          [0.8588, 0.8627, 0.8588,  ..., 0.4824, 0.5176, 0.5294],\n",
       "          [0.8667, 0.8549, 0.8392,  ..., 0.4667, 0.4784, 0.4863],\n",
       "          ...,\n",
       "          [0.7176, 0.6980, 0.6784,  ..., 0.3294, 0.3020, 0.3059],\n",
       "          [0.7059, 0.6627, 0.6353,  ..., 0.2627, 0.2627, 0.2510],\n",
       "          [0.6706, 0.6275, 0.6039,  ..., 0.2863, 0.2863, 0.2784]],\n",
       " \n",
       "         [[0.8431, 0.8510, 0.8471,  ..., 0.4549, 0.4824, 0.4980],\n",
       "          [0.8392, 0.8353, 0.8275,  ..., 0.4275, 0.4627, 0.4706],\n",
       "          [0.8392, 0.8275, 0.8078,  ..., 0.4157, 0.4235, 0.4353],\n",
       "          ...,\n",
       "          [0.6784, 0.6588, 0.6471,  ..., 0.2549, 0.2392, 0.2431],\n",
       "          [0.6667, 0.6235, 0.6000,  ..., 0.2118, 0.2196, 0.2118],\n",
       "          [0.6275, 0.5882, 0.5647,  ..., 0.2510, 0.2549, 0.2471]],\n",
       " \n",
       "         [[0.8000, 0.8039, 0.8000,  ..., 0.3922, 0.4235, 0.4392],\n",
       "          [0.7961, 0.7882, 0.7765,  ..., 0.3686, 0.4039, 0.4118],\n",
       "          [0.7961, 0.7843, 0.7608,  ..., 0.3608, 0.3686, 0.3765],\n",
       "          ...,\n",
       "          [0.6431, 0.6235, 0.6078,  ..., 0.2000, 0.1882, 0.1922],\n",
       "          [0.6275, 0.5882, 0.5647,  ..., 0.1686, 0.1843, 0.1843],\n",
       "          [0.5882, 0.5490, 0.5294,  ..., 0.2157, 0.2314, 0.2235]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_index.__getitem_wrap__(40552)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6656ba487fb895a60e5d4c5030343c34c763d6fe30d1a6683b717bdb1af8ff9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('incDFM_proj': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
