{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DFM 1-class Incremental Loop with Novelty prediction and study of error propagation\n",
    "\n",
    "All incomming data (new task) will be mixture of unseen old (iid) + new \n",
    "\n",
    "Points to note:\n",
    "1. Measure error propagation with Novelty prediction and pseudolabeling as novel/old \n",
    "2. Use predicted novel samples to update DFM with unseen label (n+1) but do not touch old parameters (for n or less)\n",
    "3. Experiment with doing prediction all at once versus in rounds (batches) guided by thresholded novelty scores or confidence values \n",
    "    3.1. Option also to discard low confidence or very low-score samples. \n",
    "4. Have option to use test set for unseen old data or to use hold-out train set \n",
    "    4.1. In the latter case, performance will also be affected because less data will be available for fitting each class originally\n",
    "\n",
    "** For now, other improvements will probably rely on having better embedding representations, most likely through some degree of finetuning while preventing overfitting (due to few data)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from matplotlib import colors as mcolors\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "import itertools\n",
    "import copy\n",
    "import yaml\n",
    "import pickle\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import tforms\n",
    "import feature_extraction.feature_extraction_utils as futils\n",
    "from feature_extraction.Network_Latents_Wrapper import NetworkLatents\n",
    "# import classifier as clf\n",
    "\n",
    "\n",
    "import novelty_dfm_CL.novelty_detector as novel\n",
    "import novelty_dfm_CL.novelty_eval as novelval \n",
    "import novelty_dfm_CL.classifier as clf\n",
    "import novelty_dfm_CL.novelty_utils as novelu\n",
    "\n",
    "\n",
    "import memory as mem\n",
    "import utils\n",
    "import datasets as dset\n",
    "import novelty_dfm_CL.datasets_holdout as dseth\n",
    "import datasets_utils as dsetutils\n",
    "\n",
    "import novelty_dfm_CL.scoring_multi_threshold as ThScores\n",
    "\n",
    "\n",
    "from novelty_dfm_CL.novelty_eval import acuracy_report, scores_metrics_results\n",
    "\n",
    "utils.seed_torch(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters defined in config yaml file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "general_config_path = '/home/amandari/CodeDev/ProjIntel/src/configs/DFM_CL_1class_loop.yaml' # path to file \n",
    "\n",
    "\n",
    "with open(general_config_path) as fid:\n",
    "        args = Namespace(**yaml.load(fid, Loader=yaml.SafeLoader))\n",
    "\n",
    "torch.set_num_threads(args.num_threads)\n",
    "pin_memory=False\n",
    "\n",
    "# set up save\n",
    "args = utils.config_saving(args)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CL setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "start=time.time()\n",
    "# 1) ----- Dataset \n",
    "if not hasattr(args, 'experiment_filepath'):\n",
    "    args.experiment_filepath = None # have dictionary for defaults???\n",
    "if not hasattr(args, 'experiment_name'):\n",
    "    args.experiment_name = None # have dictionary for defaults??\n",
    "\n",
    "\n",
    "if args.holdout:\n",
    "    # load holdout dset\n",
    "    datasets_use = dseth.call_dataset_holdout(args.dset_name, args.data_dir, args.experiment_dir, experiment_filepath=args.experiment_filepath, experiment_name=args.experiment_name, \n",
    "                                            holdout_percent=args.holdout_percent,  max_holdout=args.max_holdout, scenario=args.scenario, \n",
    "                                            scenario_classif=args.scenario_classif, exp_type=args.exp_type, num_per_task=args.num_per_task, num_classes_first=args.num_classes_first, \n",
    "                                            shuffle=args.shuffle_order, preload=False, keep_all_data=args.keep_all_data)\n",
    "\n",
    "    if args.keep_all_data==True:\n",
    "        train_datasets, train_holdout_datasets, train_datasets_new_only, test_datasets, list_tasks, dset_prep = datasets_use\n",
    "    else:\n",
    "        train_datasets, train_holdout_datasets, test_datasets, list_tasks, dset_prep = datasets_use\n",
    "\n",
    "else:\n",
    "    datasets_use = dset.call_dataset(args.dset_name, args.data_dir, args.experiment_dir, experiment_filepath=args.experiment_filepath, experiment_name=args.experiment_name, \n",
    "                                                    num_classes_first=args.num_classes_first, keep_all_data=args.keep_all_data, \n",
    "                                                    scenario=args.scenario, scenario_classif=args.scenario_classif, \n",
    "                                                    exp_type=args.exp_type, num_per_task=args.num_per_task,\n",
    "                                                    type_l_cifar=args.type_l_cifar, num_tasks_cifar=args.num_tasks_cifar, \n",
    "                                                    shuffle=args.shuffle_order, preload=False)\n",
    "    if args.keep_all_data==True:\n",
    "        train_datasets, train_datasets_new_only, test_datasets, list_tasks, dset_prep = datasets_use\n",
    "    else:\n",
    "        train_datasets, test_datasets, list_tasks, dset_prep = datasets_use\n",
    "\n",
    "\n",
    "args.dset_prep = dset_prep\n",
    "if args.num_tasks>0:\n",
    "    num_tasks = args.num_tasks\n",
    "else:\n",
    "    num_tasks = len(train_datasets)\n",
    "\n",
    "test_loaders = [torch.utils.data.DataLoader(test_datasets[t], batch_size=args.batchsize_test,\n",
    "                                                shuffle=True, num_workers=args.num_workers) for t in range(num_tasks)]\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "first_task [0, 1] 1 0\n",
      "seq_tasks:  [[0, 1], [2], [3], [4], [5], [6], [7], [8], [9]]\n",
      "*****Prep Data*****\n",
      "Prepare DSET npy paths\n",
      "prepared filelists 0.38440680503845215\n",
      "None\n",
      "number tasks 9\n",
      "prepared datasets 5.950266599655151\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "if args.holdout:\n",
    "    old_dsets = train_holdout_datasets\n",
    "    use_old_dsets = copy.copy(train_holdout_datasets)\n",
    "else:\n",
    "    old_dsets = test_datasets\n",
    "    use_old_dsets = copy.copy(test_datasets)\n",
    "\n",
    "\n",
    "num_old_per_task = {}\n",
    "for t_w in range(1,num_tasks):\n",
    "    print('Get scores for novelty detector')\n",
    "    # how much to mix from old and new in one task\n",
    "    num_old, num_new, num_old_per_task_pt = novelu.num_mix_old_novelty(args.percent_old_mix, train_datasets[t_w], old_dsets[:t_w], t_w, list_tasks)\n",
    "    print('Task', t_w, 'num_old', num_old,  'num_new', num_new, 'num_old_per_task', num_old_per_task_pt)\n",
    "    num_old_per_task[t_w] = num_old_per_task_pt\n",
    "\n",
    "print('Data set up', time.time()-start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2) ------ Network \n",
    "if len(args.fc_sizes)>0:\n",
    "    fc_sizes = args.fc_sizes.split(\",\")\n",
    "    fc_sizes = [int(x) for x in fc_sizes]\n",
    "else:\n",
    "    fc_sizes = []\n",
    "network = clf.Resnet(dset_prep['total_classes'], resnet_arch=args.net_type, FC_layers=fc_sizes, base_freeze=True)\n",
    "network = network.to(args.device)\n",
    "dfm_inputs = args.dfm_layers_input.split(\",\")\n",
    "dfm_layers_factors = str(args.dfm_layers_factors)\n",
    "dfm_layers_factors = dfm_layers_factors.split(',')\n",
    "dfm_inputs_factors = {}\n",
    "for n in range(len(dfm_inputs)):\n",
    "    dfm_inputs_factors[dfm_inputs[n]]=int(dfm_layers_factors[n]) #adaptive pooling \n",
    "network_inner = NetworkLatents(network, dfm_inputs, pool_factors=dfm_inputs_factors)\n",
    "print('Network set up', time.time()-start)\n",
    "\n",
    "\n",
    "args.patience_lr = int(np.ceil(args.schedule_patience_perepoch*args.num_epochs))\n",
    "\n",
    "\n",
    "# 3) ---- Novelty\n",
    "args.detector_params['target_ind']=dset_prep['scenario_classif']\n",
    "args.detector_params['device']=args.device\n",
    "if args.novelty_detector_name=='odin':\n",
    "    args.detector_params['base_network']=network #simple network (not wrapper) - Is this problematic? TODO\n",
    "    args.detector_params['num_classes']=dset_prep['total_classes']\n",
    "    args.detector_params['criterion']= nn.CrossEntropyLoss()\n",
    "    args.detector_params['num_epochs']=args.num_epochs\n",
    "    args.detector_params['train_technique']=args.train_technique\n",
    "    args.detector_params['lr']=args.lr\n",
    "    args.detector_params['patience_lr'] = args.patience_lr\n",
    "    args.detector_params['schedule_decay'] = args.schedule_decay\n",
    "    args.detector_params['step_size_epoch_lr']= args.step_size_epoch_lr\n",
    "    args.detector_params['gamma_step_lr']= args.gamma_step_lr\n",
    "\n",
    "\n",
    "\n",
    "noveltyResults = novelval.save_novelty_results(num_tasks, args.experiment_name_plot, args.dir_save)\n",
    "novelty_detector = novel.NoveltyDetector().create_detector(type=args.novelty_detector_name, params=args.detector_params)\n",
    "print('Novelty Detector set up', time.time()-start)\n",
    "\n",
    "\n",
    "# 4) ---- Memory (if applicable for recomputing DFM per task)\n",
    "# Use raw images in memory\n",
    "coreset = None\n",
    "if args.coreset_size>0:\n",
    "    if args.use_image_as_input:\n",
    "        raw_sizes = {'svhn':32, 'cifar10':32, 'cifar100':32}\n",
    "        input_size = 3*(raw_sizes[args.dset_name]**2)\n",
    "    else:\n",
    "        input_size = network.feat_size  \n",
    "    if args.coreset_size>0 and args.keep_all_data==False:\n",
    "        if args.coreset_size_MB>0:\n",
    "            coreset_size = utils.memory_equivalence(args.coreset_size_MB, input_size, quantizer_dict=None)\n",
    "        else:\n",
    "            coreset_size = args.coreset_size\n",
    "        coreset = mem.CoresetDynamic(coreset_size, target_ind= dset_prep['scenario_classif'], homog_ind=dset_prep['homog_ind'], device=args.device)\n",
    "print('Memory set up', time.time()-start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Get scores for novelty detector\n",
      "Task 1 num_old 2000 num_new 4000 num_old_per_task [2000]\n",
      "Get scores for novelty detector\n",
      "Task 2 num_old 3000 num_new 4000 num_old_per_task [1500 1500]\n",
      "Get scores for novelty detector\n",
      "Task 3 num_old 4000 num_new 4000 num_old_per_task [1334 1333 1333]\n",
      "Get scores for novelty detector\n",
      "Task 4 num_old 4000 num_new 4000 num_old_per_task [1000 1000 1000 1000]\n",
      "Get scores for novelty detector\n",
      "Task 5 num_old 4000 num_new 4000 num_old_per_task [800 800 800 800 800]\n",
      "Get scores for novelty detector\n",
      "Task 6 num_old 4000 num_new 4000 num_old_per_task [667 667 667 666 666 667]\n",
      "Get scores for novelty detector\n",
      "Task 7 num_old 4000 num_new 4000 num_old_per_task [571 572 572 572 571 571 571]\n",
      "Get scores for novelty detector\n",
      "Task 8 num_old 4000 num_new 4000 num_old_per_task [500 500 500 500 500 500 500 500]\n",
      "Data set up 58.57536482810974\n",
      "load contrastive backbone\n",
      "Will fetch activations from:\n",
      "base.8, average pooled by -1\n",
      "Network set up 59.25903606414795\n",
      "Novelty Detector set up 59.26430654525757\n",
      "Memory set up 59.265056848526\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-step Thresholding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CL Loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "per_task_results = {'scores':{}, 'scores_dist':{}, 'gt_novelty':{}, 'gt':{}, 'inds':{}, 'threshold':{}, 'preds':{}}\n",
    "\n",
    "per_task_results = Namespace(**per_task_results)\n",
    "\n",
    "num_classes = 0\n",
    "for t in range(num_tasks):\n",
    "    print('###############################')\n",
    "    print('######### task %d ############'%(t))\n",
    "    print('###############################')\n",
    "    current_task = list_tasks[t]\n",
    "\n",
    "\n",
    "    # ------- Set up data \n",
    "    if t>0 and (coreset is not None):\n",
    "        batchsize_new =  int(args.batchsize*0.5)\n",
    "        batchsize_old = args.batchsize - batchsize_new\n",
    "        # --- wrap old data features (latent)\n",
    "        dataset_old = dsetutils.DSET_wrapper_Replay(coreset.coreset_im, coreset.coreset_t, latents=coreset.coreset_latents, transform=args.tf_coreset)\n",
    "        loader_old = torch.utils.data.DataLoader(dataset_old, batch_size=batchsize_old,\n",
    "                                                shuffle=True, num_workers=args.num_workers)\n",
    "    else:\n",
    "        batchsize_new = args.batchsize\n",
    "        batchsize_old = 0\n",
    "        loader_old = None\n",
    "        \n",
    "\n",
    "    if t>0:\n",
    "        # 1) get appropriate \"current data\"\n",
    "        if args.keep_all_data==True:\n",
    "            new_data = train_datasets_new_only[t]\n",
    "        else:\n",
    "            new_data = train_datasets[t]\n",
    "\n",
    "        print('Get scores for novelty detector')\n",
    "        for t_old in range(t):\n",
    "            use_old_dsets[t_old].select_random_subset(num_old_per_task[t][t_old])\n",
    "\n",
    "        current_dset = novelu.CurrentTask(new_data, use_old_dsets[:t])\n",
    "\n",
    "        current_loader = torch.utils.data.DataLoader(current_dset, batch_size=args.batchsize_test,\n",
    "                                                shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "        params_score = {'layer':args.dfm_layers_input, 'feature_extractor':network_inner, \\\n",
    "            'base_apply_score':True, 'target_ind':dset_prep['scenario_classif']}\n",
    "\n",
    "\n",
    "        if args.threshold_type=='simple':\n",
    "            # 2) Threshold Novel/Old - Binary prediction \n",
    "            if args.novelty_detector_name=='dfm':\n",
    "                results_novelty = novelval.evaluate_dfm_CL(t, novelty_detector, noveltyResults, params_score, current_loader)\n",
    "            elif args.novelty_detector_name=='odin':\n",
    "                results_novelty = novelval.evaluate_odin_CL(t, novelty_detector, noveltyResults, params_score, current_loader)\n",
    "            inds_pred_novel,_ = novelu.Threshold_n_Select_Simple(t, results_novelty, th_percentile_score=args.threshold_percentile, novelty_detector_name=args.novelty_detector_name, \n",
    "                                th_percentile_confidence=args.th_percentile_confidence,  metric_confidence=(args.metric_confidence, args.metric_confidence_direction_novel))\n",
    "            threshold_used = args.threshold_percentile\n",
    "        else:\n",
    "            args.params_score = Namespace(**params_score)\n",
    "            args.num_samples = current_dset.__len__()\n",
    "            args.th_percentile = args.threshold_percentile\n",
    "            args.w = args.w_score\n",
    "            # Threshold_n_Select_Iters(params)\n",
    "            SelectTh = novelu.Threshold_n_Select_Iters(args)\n",
    "            inds_pred_novel = SelectTh.select_novel(current_dset, novelty_detector)\n",
    "            results_novelty = SelectTh.evaluate_CL(t, current_dset, novelty_detector, noveltyResults)\n",
    "            threshold_used = args.max_threshold_total\n",
    "\n",
    "                    \n",
    "        # store results per task \n",
    "        per_task_results.scores_dist[t] = results_novelty.scores_dist\n",
    "        per_task_results.scores[t] = results_novelty.scores\n",
    "        per_task_results.gt_novelty[t] = results_novelty.gt_novelty\n",
    "        per_task_results.gt[t] = results_novelty.gt\n",
    "        per_task_results.inds[t] = results_novelty.dset_inds\n",
    "        per_task_results.threshold[t] = threshold_used\n",
    "\n",
    "        preds_array = np.zeros(results_novelty.scores.shape)\n",
    "        preds_array[inds_pred_novel]=1\n",
    "        per_task_results.preds[t] = preds_array\n",
    "\n",
    "\n",
    "        # 3) Pseudolabel \"Novel\" Samples\n",
    "        if args.prediction_propagation:\n",
    "            print('Use Predicted Labels for Propagation/DFM Fit')\n",
    "            loader_new = torch.utils.data.DataLoader(novelu.NovelTask(t, num_classes, current_dset, pred_novel_inds=inds_pred_novel), batch_size=batchsize_new,\n",
    "                                                    shuffle=True, num_workers=args.num_workers)\n",
    "        else:\n",
    "            inds_gt_novel = np.where(current_dset.novelty_y==1)[0]\n",
    "            print('Use Ground Truth Labels for Propagation/DFM Fit')\n",
    "            loader_new = torch.utils.data.DataLoader(novelu.NovelTask(t, num_classes, current_dset, pred_novel_inds=inds_gt_novel), batch_size=batchsize_new,\n",
    "                                                    shuffle=True, num_workers=args.num_workers)\n",
    "\n",
    "    else:\n",
    "        loader_new = torch.utils.data.DataLoader(novelu.NovelTask(t, num_classes, train_datasets[t]), batch_size=batchsize_new, shuffle=True, num_workers=args.num_workers)\n",
    "\n",
    "\n",
    "    # if training classifier or doing finetuning of backbone \n",
    "    if args.train_clf:\n",
    "        clf.train(t, args, novelty_detector, network_inner, loader_old, loader_new, test_loaders, train_technique=args.train_technique)\n",
    "\n",
    "    #  call training loop with one liner \n",
    "    args, temp_train_loader = novelu.temporary_loader_novelty(args, loader_new, coreset)\n",
    "\n",
    "\n",
    "\n",
    "    print('Generate features for novelty evaluation and coreset')\n",
    "    processed_data = futils.extract_features(network_inner, temp_train_loader, \\\n",
    "        target_ind=dset_prep['scenario_classif'], homog_ind=1, \n",
    "        device=args.device, use_raw_images=args.use_image_as_input, raw_image_transform=args.add_tf)\n",
    "\n",
    "\n",
    "\n",
    "    # ----Update memory and Novelty detector\n",
    "    if t<num_tasks-1:\n",
    "\n",
    "        if args.novelty_detector_name=='dfm':\n",
    "            dfm_x = processed_data[0][args.dfm_layers_input]\n",
    "            dfm_y = processed_data[1]\n",
    "            if args.finetune_backbone=='all':\n",
    "                novelty_detector, dfm_x, dfm_y = novelu.reprocess_data_novelty(args, dfm_x, dfm_y, network_inner, coreset)\n",
    "            novelty_detector.fit_total(dfm_x.T, dfm_y)\n",
    "\n",
    "\n",
    "        # ------ update coreset (if applicable)\n",
    "        if coreset is not None:\n",
    "            print('Append data to memory')\n",
    "            coreset.append_memory(processed_data, current_task)\n",
    "            print('coreset_im', coreset.coreset_im.shape)\n",
    "\n",
    "\n",
    "    num_classes = num_classes + len(current_task)\n",
    "\n",
    "\n",
    "    sys.exit()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "###############################\n",
      "######### task 0 ############\n",
      "###############################\n",
      "##########epoch 0###########\n",
      "Number batches:  160\n",
      "Train Epoch: 0 [0/160 (0.000)]\tLoss: 2.3038\tAcc_Train_new:0.040\n",
      "Train Epoch: 0 [10/160 (6.250)]\tLoss: 2.1553\tAcc_Train_new:0.660\n",
      "Train Epoch: 0 [20/160 (12.500)]\tLoss: 1.9209\tAcc_Train_new:0.840\n",
      "Train Epoch: 0 [30/160 (18.750)]\tLoss: 1.7314\tAcc_Train_new:0.760\n",
      "Train Epoch: 0 [40/160 (25.000)]\tLoss: 1.5699\tAcc_Train_new:0.600\n",
      "Train Epoch: 0 [50/160 (31.250)]\tLoss: 1.4729\tAcc_Train_new:0.520\n",
      "Train Epoch: 0 [60/160 (37.500)]\tLoss: 1.4238\tAcc_Train_new:0.440\n",
      "Train Epoch: 0 [70/160 (43.750)]\tLoss: 1.3124\tAcc_Train_new:0.560\n",
      "Train Epoch: 0 [80/160 (50.000)]\tLoss: 1.2559\tAcc_Train_new:0.580\n",
      "Train Epoch: 0 [90/160 (56.250)]\tLoss: 1.3151\tAcc_Train_new:0.420\n",
      "Train Epoch: 0 [100/160 (62.500)]\tLoss: 1.2285\tAcc_Train_new:0.520\n",
      "Train Epoch: 0 [110/160 (68.750)]\tLoss: 1.2637\tAcc_Train_new:0.440\n",
      "Train Epoch: 0 [120/160 (75.000)]\tLoss: 1.2387\tAcc_Train_new:0.440\n",
      "Train Epoch: 0 [130/160 (81.250)]\tLoss: 1.1967\tAcc_Train_new:0.440\n",
      "Train Epoch: 0 [140/160 (87.500)]\tLoss: 1.1638\tAcc_Train_new:0.500\n",
      "Train Epoch: 0 [150/160 (93.750)]\tLoss: 1.1005\tAcc_Train_new:0.600\n",
      "**************TEST****************\n",
      "*********************************************************\n",
      "****************Testing task 0************\n",
      "*********************************************************\n",
      "\n",
      " Per-Task Test set: Accuracy: {1000}/{2000} = {50.0000}\n",
      "\n",
      "\n",
      " ******Test set: Average Accuracy: 50.0000*****\n",
      "\n",
      "Generate features for novelty evaluation and coreset\n",
      "Append data to memory\n",
      "*******Appending to CORESET******\n",
      "total_size 5000 room_new 5000 room_left 5000 coreset now 0\n",
      "coreset_im torch.Size([5000, 2048])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/amandari/miniconda3/envs/remind_proj/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Dist Scores + Ground Truth "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "with open('%s/results_tasks.pickle'%(args.dir_save), 'wb') as handle:\n",
    "    pickle.dump(per_task_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('remind_proj': conda)"
  },
  "interpreter": {
   "hash": "05b150e87e16a7f15e68a52cad20b8449e4511c9ed1c6048915793505d6c322d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}